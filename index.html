<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Jinglin Xu</title>
  
  <meta name="author" content="Jinglin Xu">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/USTB_logo.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
	      <div id="CNVer" style="left: 375px" class="floatleft">
		      <a href="https://learn-in-practice.github.io/">[中文版]</a>
	      </div>
              <p style="text-align:center">
                <name>Jinglin Xu</name>
              </p>
              <p style="text-align: justify;">  <strong>Jinglin Xu</strong> is now an Associate Professor at the School of Intelligence Science and Technology, University of Science and Technology Beijing. She received the National Natural Science Foundation of China (NSFC) Young Scientists Fund (Category B, formerly the Excellent Young Scientists Fund). She serves as the Director and Deputy Secretary-General of the Beijing Society of Image and Graphics, as well as Vice Chair of the Youth Talent Support Club of the China Society of Image and Graphics. Her research interests include computer vision, video understanding, and fine-grained motion analysis. She has published more than 30 academic papers on the top-tier ACM/IEEE Transactions and CCF A-class journals and conferences, such as TPAMI, IJCV, CVPR, etc. She has led projects including the NSFC General Program, the NSFC Young Scientists Fund, the Beijing Natural Science Foundation General Program, the China Postdoctoral Science Foundation General Program, and the Tencent Rhino-Bird Special Research Program. She participated in the National Natural Science Foundation of China Key Project (ranked 2nd) and the Beijing Natural Science Foundation Joint Fund Key Project (ranked 2nd) as the head of the cooperative unit. She has collaborated with organizations such as China Telecom and Tencent to advance the application of scientific research achievements in practical scenarios. She was selected into the China Association for Science and Technology Youth Talent Support Program and has received the Shi Qingyun Female Scientist Award and the Outstanding Doctoral Dissertation Award from the China Society of Image and Graphics. Additionally, she has received the First Prize in the Natural Science Award (ranked 4/5) from the Chinese Association of Automation and the Second Prize in the Natural Science Award (ranked 3/5) from the China Society of Image and Graphics. She serves as a Youth Editorial Board Member of the Chinese Journal of Electronics, an Editorial Board Member of the Journal of Electronics & Information Technology, and the Program Committee Member for IJCAI/AAAI.
                 </p>
              </p>
	      <p style="text-align: justify;"> <font color="red"><strong>We actively recruit Post-doc Fellows, Ph.D./Master students, and Research Interns! Welcome to contact me with your detailed CV!</strong></font>
		    </p>
              <p style="text-align:center">
                <a href="mailto:xujinglin@ustb.edu.cn"> Email </a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?hl=en&tzom=-480&user=SVFP5XEAAAAJ"> Google Scholar </a> &nbsp/&nbsp
                <a href="https://github.com/xujinglin"> GitHub </a> 
              </p>
            </td>
            <td style="padding:2.5%;width:30%;max-width:30%">
              <a href="images/xujinglin.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/xujinglin.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>

		

	    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>News</heading>
          <p>
		  <li style="margin: 5px;" >
		 2025-07-10：1 paper has been accepted to TCSVT 2025.
	</li>
		  <li style="margin: 5px;" >
		 2025-03-28：1 paper has been accepted to TPAMI 2025.
	</li>
		  <li style="margin: 5px;" >
		 2025-03-01：1 paper has been accepted to TCSVT 2025.
	</li>
			  <li style="margin: 5px;" >
		 2025-02-27：1 paper has been accepted to CVPR 2025.
	</li>
		  <li style="margin: 5px;" >
		 2025-01-25：1 paper has been accepted to TPAMI 2025.
	</li>
		   <li style="margin: 5px;" >
		 2025-01-23：2 paper has been accepted to ICLR 2025.
	</li>

            </p>
          </td>
        </tr>

	</tbody></table>

	  
		
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Grants</heading>
              <p>
    <li style="margin: 5px;" >
                  National Natural Science Foundation of China (Young Scientists Fund Category B), 2025.
		              </li>
		<li style="margin: 5px;" >
                  Natural Science Foundation of Beijing (General Program), 2025.
		              </li>
		<li style="margin: 5px;" >
                  National Natural Science Foundation of China (General Program), 2023.
                </li>
		<li style="margin: 5px;" >
                  National Natural Science Foundation of China (Key Program), 2024, (Participation).
                </li> 
		 <li style="margin: 5px;" >
                  Natural Science Foundation of Beijing (Key Program), 2024, (Participation).
                </li> 
                <li style="margin: 5px;" >
                  National Natural Science Foundation of China (Youth Science Foundation), 2021.
<!--                 </li>
                <li style="margin: 5px;" >
                  China Postdoctoral Science Foundation, 2020.
                </li>
                <li style="margin: 5px;" >
                  Innovation Foundation for Doctor Dissertation of Northwestern Polytechnical University, 2018.
                </li> -->
  
              </p>
            </td>
          </tr>
  </tbody></table>

	  	  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Honors and Awards</heading>
          <p>
		  <li style="margin: 5px;" >
		 China Society of Image and Graphics Shi QingYun Female Scientist Award, 2024
	</li>
		  
                <li style="margin: 5px;" >
		 The 9th Young Elite Scientists Sponsorship Program by CAST, 2023
	</li>
		    <li style="margin: 5px;" >
		  Excellent Doctoral Dissertation Award of CSIG, 2022.
          </li>
		    <li style="margin: 5px;" >
                  The First Prize of Natural Science Award of CAA, 2023, (4/5)
           </li>
		    <li style="margin: 5px;" >
                  The Second Prize of Natural Science Award of CSIG, 2024, (3/5)
           </li>
<!-- 		    <li style="margin: 5px;" >
		    Excellent Doctoral Dissertation of Northwestern Polytechnical University, 2022.
	     </li>
		          <li style="margin: 5px;" >
                Excellent Graduate of Northwestern Polytechnical University, 2020.
              </li>
		          <li style="margin: 5px;" >
                National Scholarship, Ministry of Education of P.R. China, 2017, 2018.
              </li>
			  <li style="margin: 5px;" >
                Outstanding Graduate Student of Northwestern Polytechnical University, 2016, 2017, 2018.
              </li> -->

            </p>
          </td>
        </tr>

	</tbody></table>
	  
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Selected Publications</heading>
			  <p></p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>


<tr>
              <td style="padding:20px;width:30%;max-width:30%" align="center">
                  <img style="width:100%;max-width:100%" src='images/HC-FGAQA.png' alt="dise">
              </td>
              <td width="75%" valign="center">
                  <papertitle>Human-centric Fine-grained Action Quality Assessment</papertitle>
                  <br>
                  <strong>Jinglin Xu</strong>, Sibo Yin, Yuxin Peng*
                  <br>
                  <em>IEEE Transactions on Pattern Analysis and Machine Intelligence (<strong>TPAMI</strong>)</em>, 2025
                  <br>
<!--                   <a href="https://finediving.ivg-research.xyz/">[Project Page]</a> -->
<!--                   <a href="https://github.com/xujinglin/TransferableUAL">[Github]</a> -->
                  <a href="https://ieeexplore.ieee.org/document/10946879">[Paper]</a>
<!--                   <a href="data/ProDiff.txt">[bibtex]</a> -->
<!--                   <a href="http://39.108.48.32/mipl/news/news.php?id=20240902">[中文解读]</a> -->
                  <br>
              </td>
          </tr>


		
		<tr>
              <td style="padding:20px;width:30%;max-width:30%" align="center">
                  <img style="width:100%;max-width:100%" src='images/TransferableUAL.png' alt="dise">
              </td>
              <td width="75%" valign="center">
                  <papertitle>Transferable Unintentional Action Localization with Language-guided Intention Translation</papertitle>
                  <br>
                  <strong>Jinglin Xu</strong>, Yongming Rao, Jie Zhou, Jiwen Lu*
                  <br>
                  <em>IEEE Transactions on Pattern Analysis and Machine Intelligence (<strong>TPAMI</strong>)</em>, 2025
                  <br>
<!--                   <a href="https://finediving.ivg-research.xyz/">[Project Page]</a> -->
<!--                   <a href="https://github.com/xujinglin/TransferableUAL">[Github]</a> -->
                  <a href="https://ieeexplore.ieee.org/document/10872809">[Paper]</a>
<!--                   <a href="data/ProDiff.txt">[bibtex]</a> -->
<!--                   <a href="http://39.108.48.32/mipl/news/news.php?id=20240902">[中文解读]</a> -->
                  <br>
              </td>
          </tr>



<tr>
              <td style="padding:20px;width:30%;max-width:30%" align="center">
                  <img style="width:100%;max-width:100%" src='images/DyFo.png' alt="dise">
              </td>
              <td width="75%" valign="center">
                  <papertitle>DyFo: A Training-Free Dynamic Focus Visual Search for Enhancing LMMs in Fine-Grained Visual Understanding</papertitle>
                  <br>
                  Geng Li, <strong>Jinglin Xu</strong>, Yunzhen Zhao, Yuxin Peng*
                  <br>
                  <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</em>, 2025
                  <br>
<!--                   <a href="https://finediving.ivg-research.xyz/">[Project Page]</a> -->
                  <a href="https://github.com/PKU-ICST-MIPL/DyFo_CVPR2025">[Github]</a>
                  <a href="https://openaccess.thecvf.com/content/CVPR2025/papers/Li_DyFo_A_Training-Free_Dynamic_Focus_Visual_Search_for_Enhancing_LMMs_CVPR_2025_paper.pdf">[Paper]</a>
<!--                   <a href="data/ProDiff.txt">[bibtex]</a> -->
<!--                   <a href="http://39.108.48.32/mipl/news/news.php?id=20250123">[中文解读]</a> -->
                  <br>
              </td>
          </tr>

		

<tr>
              <td style="padding:20px;width:30%;max-width:30%" align="center">
                  <img style="width:100%;max-width:100%" src='images/MLLMs.jpg' alt="dise">
              </td>
              <td width="75%" valign="center">
                  <papertitle>Analyzing and Boosting the Power of Fine-Grained Visual Recognition for Multi-modal Large Language Models</papertitle>
                  <br>
                  Hulingxiao He, Geng Li, Zijun Geng, <strong>Jinglin Xu</strong>, Yuxin Peng*
                  <br>
                  <em>International Conference on Learning Representations (<strong>ICLR</strong>)</em>, 2025
                  <br>
<!--                   <a href="https://finediving.ivg-research.xyz/">[Project Page]</a> -->
                  <a href="https://github.com/PKU-ICST-MIPL/Finedefics_ICLR2025">[Github]</a>
                  <a href="https://arxiv.org/abs/2501.15140">[Paper]</a>
<!--                   <a href="data/ProDiff.txt">[bibtex]</a> -->
                  <a href="http://39.108.48.32/mipl/news/news.php?id=20250123">[中文解读]</a>
                  <br>
              </td>
          </tr>
		

		<tr>
              <td style="padding:20px;width:30%;max-width:30%" align="center">
                  <img style="width:100%;max-width:100%" src='images/MAI.jpg' alt="dise">
              </td>
              <td width="75%" valign="center">
                  <papertitle>MAI: A Multi-turn Aggregation-Iteration Model for Composed Image Retrieval</papertitle>
                  <br>
                  Yanzhe Chen, Zhiwen Yang, <strong>Jinglin Xu</strong>, Yuxin Peng*
                  <br>
                  <em>International Conference on Learning Representations (<strong>ICLR</strong>)</em>, 2025
                  <br>
<!--                   <a href="https://finediving.ivg-research.xyz/">[Project Page]</a> -->
<!--                   <a href="https://github.com/PKU-ICST-MIPL/FineFMPL_IJCAI2024">[Github]</a> -->
                  <a href="https://openreview.net/pdf?id=gXyWbl71n1">[Paper]</a>
<!--                   <a href="data/ProDiff.txt">[bibtex]</a> -->
                  <a href="http://39.108.48.32/mipl/news/news.php?id=20250123">[中文解读]</a>
                  <br>
              </td>
          </tr>

<tr>
              <td style="padding:20px;width:30%;max-width:30%" align="center">
                  <img style="width:100%;max-width:100%" src='images/BFSTAL-pipeline.png' alt="dise">
              </td>
              <td width="75%" valign="center">
                  <papertitle>BFSTAL: Bidirectional Feature Splitting with Cross-Layer Fusion for Temporal Action Localization</papertitle>
                  <br>
                  <strong>Jinglin Xu</strong>, Yaqi Zhang, Wenhao Zhou, Hongmin Liu*
                  <br>
                  <em>IEEE Transactions on Circuits and Systems for Video Technology (<strong>TCSVT</strong>)</em>, 2025
                  <br>
<!--                   <a href="https://finediving.ivg-research.xyz/">[Project Page]</a> -->
<!--                   <a href="https://github.com/PKU-ICST-MIPL/FineFMPL_IJCAI2024">[Github]</a> -->
                  <a href="https://ieeexplore.ieee.org/abstract/document/11079712">[Paper]</a>
                  <!-- <a href="data/BRTAL.txt">[bibtex]</a> -->
<!--                   <a href="http://39.108.48.32/mipl/news/news.php?id=20240902">[中文解读]</a> -->
                  <br>
              </td>
          </tr>

<tr>
              <td style="padding:20px;width:30%;max-width:30%" align="center">
                  <img style="width:100%;max-width:100%" src='images/TCSVT-BRTAL.png' alt="dise">
              </td>
              <td width="75%" valign="center">
                  <papertitle>BRTAL: Boundary Refinement Temporal Action Localization via Offset-Driven Diffusion Models</papertitle>
                  <br>
                  Hongmin Liu, Xueli Li, Bin Fan, <strong>Jinglin Xu*</strong>
                  <br>
                  <em>IEEE Transactions on Circuits and Systems for Video Technology (<strong>TCSVT</strong>)</em>, 2025
                  <br>
<!--                   <a href="https://finediving.ivg-research.xyz/">[Project Page]</a> -->
<!--                   <a href="https://github.com/PKU-ICST-MIPL/FineFMPL_IJCAI2024">[Github]</a> -->
                  <a href="https://ieeexplore.ieee.org/document/10912675">[Paper]</a>
                  <a href="data/BRTAL.txt">[bibtex]</a>
<!--                   <a href="http://39.108.48.32/mipl/news/news.php?id=20240902">[中文解读]</a> -->
                  <br>
              </td>
          </tr>
		
		
		<tr>
              <td style="padding:20px;width:30%;max-width:30%" align="center">
                  <img style="width:100%;max-width:100%" src='images/TIP-Pro2Diff.png' alt="dise">
              </td>
              <td width="75%" valign="center">
                  <papertitle>Pro2Diff: Proposal Propagation for Multi-Object Tracking via Diffusion Models</papertitle>
                  <br>
                  Hongmin Liu, Canbin Zhang, Bin Fan, <strong>Jinglin Xu*</strong>
                  <br>
                  <em>IEEE Transactions on Image Processing (<strong>TIP</strong>)</em>, 2024
                  <br>
<!--                   <a href="https://finediving.ivg-research.xyz/">[Project Page]</a> -->
<!--                   <a href="https://github.com/PKU-ICST-MIPL/FineFMPL_IJCAI2024">[Github]</a> -->
                  <a href="https://ieeexplore.ieee.org/document/10753449">[Paper]</a>
                  <a href="data/ProDiff.txt">[bibtex]</a>
<!--                   <a href="http://39.108.48.32/mipl/news/news.php?id=20240902">[中文解读]</a> -->
                  <br>
              </td>
          </tr>
		
		
	<tr>
              <td style="padding:20px;width:30%;max-width:30%" align="center">
                  <img style="width:100%;max-width:100%" src='images/SIM-OFE.png' alt="dise">
              </td>
              <td width="75%" valign="center">
                  <papertitle>SIM-OFE: Structure Information Mining and Object-aware Feature Enhancement for Fine-Grained Visual Categorization</papertitle>
                  <br>
                  Hongbo Sun, Xiangteng He, <strong>Jinglin Xu</strong>, Yuxin Peng*
                  <br>
                  <em>IEEE Transactions on Image Processing (<strong>TIP</strong>)</em>, 2024
                  <br>
<!--                   <a href="https://finediving.ivg-research.xyz/">[Project Page]</a> -->
<!--                   <a href="https://github.com/PKU-ICST-MIPL/FineFMPL_IJCAI2024">[Github]</a> -->
                  <a href="https://ieeexplore.ieee.org/document/10684043">[Paper]</a>
                  <!-- <a href="https://">[bibtex]</a> -->
                  <a href="http://39.108.48.32/mipl/news/news.php?id=20240902">[中文解读]</a>
                  <br>
              </td>
          </tr>
          
      <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
                <img style="width:100%;max-width:100%" src='images/SIA-OVD.png' alt="dise">
            </td>
            <td width="75%" valign="center">
                <papertitle>SIA-OVD: Shape-Invariant Adapter for Bridging the Image-Region Gap in Open-Vocabulary Detection</papertitle>
                <br>
                Zishuo Wang, Wenhao Zhou, <strong>Jinglin Xu</strong>, Yuxin Peng*
                <br>
                <em>ACM International Conference on Multimedia (<strong>ACM MM</strong>)</em>, 2024
                <br>
                <!-- <a href="https://">[Project Page]</a> -->
                <a href="https://github.com/PKU-ICST-MIPL/SIA-OVD_ACMMM2024">[Github]</a>
                <a href="https://openreview.net/pdf/5ac4f0c72baeb04afa192b58ff05f52534a58e61.pdf">[Paper]</a>
                <!-- <a href="https://">[bibtex]</a> -->
                <a href="http://39.108.48.32/mipl/news/news.php?id=20240717">[中文解读]</a>
                <br>
            </td>
        </tr>


<tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src='images/FineDiving-IJCV.png' alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>Procedure-aware Action Quality Assessment: Datasets and Performance Evaluation</papertitle>
              <br>
			        <strong>Jinglin Xu</strong>, Yongming Rao, Jie Zhou, Jiwen Lu*
              <br>
              <em>International Journal of Computer Vision (<strong>IJCV</strong>)</em>, 2024
              <br>
<!--               <a href="https://finediving.ivg-research.xyz/">[Project Page]</a> -->
	      <a href="https://github.com/xujinglin/FineDiving">[Github]</a>
	      <a href="https://link.springer.com/article/10.1007/s11263-024-02146-z">[Paper]</a>
<!--               <a href="data/finediving.txt">[bibtex]</a> -->
<!--               <a href="https://zhuanlan.zhihu.com/p/495367542">[中文解读]</a>  -->
              <br>
            </td>
            </tr>

			
	<tr>
              <td style="padding:20px;width:30%;max-width:30%" align="center">
                  <img style="width:100%;max-width:100%" src='images/FineFMPL.png' alt="dise">
              </td>
              <td width="75%" valign="center">
                  <papertitle>FineFMPL: Fine-grained Feature Mining Prompt Learning for Few-Shot Class Incremental Learning</papertitle>
                  <br>
                  Hongbo Sun, Jiahuan Zhou, Xiangteng He, <strong>Jinglin Xu</strong>, Yuxin Peng*
                  <br>
                  <em>International Joint Conference on Artificial Intelligence (<strong>IJCAI</strong>)</em>, 2024
                  <br>
                  <!-- <a href="https://finediving.ivg-research.xyz/">[Project Page]</a> -->
                  <a href="https://github.com/PKU-ICST-MIPL/FineFMPL_IJCAI2024">[Github]</a>
                  <a href="https://www.ijcai.org/proceedings/2024/144">[Paper]</a>
                  <!-- <a href="https://">[bibtex]</a> -->
                  <!-- <a href="https://">[中文解读]</a> -->
                  <br>
              </td>
          </tr>

			  <tr>
              <td style="padding:20px;width:30%;max-width:30%" align="center">
                  <img style="width:100%;max-width:100%" src='images/ScalableTrack.png' alt="dise">
              </td>
              <td width="75%" valign="center">
                  <papertitle>ScalableTrack: Scalable One-stream Tracking via Stage-continual Learning</papertitle>
                  <br>
                  Hongmin Liu, Yuefeng Cai, Bin Fan, <strong>Jinglin Xu*</strong>
                  <br>
                  <em>IEEE Transactions on Neural Networks and Learning Systems (<strong>TNNLS</strong>)</em>, 2024
                  <br>
                  <!-- <a href="https://finediving.ivg-research.xyz/">[Project Page]</a> -->
                  <!-- <a href="https://github.com/PKU-ICST-MIPL/FineFMPL_IJCAI2024">[Github]</a>-->
                  <a href="https://ieeexplore.ieee.org/abstract/document/10552317">[Paper]</a>
                  <!-- <a href="https://">[bibtex]</a> -->
                  <!-- <a href="https://">[中文解读]</a> -->
                  <br>
              </td>
          </tr>

			  
      <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src='images/FineParser.png' alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>FineParser: A Fine-grained Spatio-temporal Action Parser for Human-centric Action Quality Assessment</papertitle>
              <br>
			  <strong>Jinglin Xu</strong>, Sibo Yin, Guohao Zhao, Zishuo Wang, Yuxin Peng*
		
              <br>
              <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</em>, 2024
		      <br>
		      <font color="red"><strong>Oral (3.3%)</strong></font>
        <br>
	      <a href="https://pku-icst-mipl.github.io/FineParser_ProjectPage/">[Project Page]</a>
        <a href="https://github.com/PKU-ICST-MIPL/FineParser_CVPR2024">[Github]</a>
	      <a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Xu_FineParser_A_Fine-grained_Spatio-temporal_Action_Parser_for_Human-centric_Action_Quality_CVPR_2024_paper.pdf">[Paper]</a>
	      <a href="data/FineParser.txt">[bibtex]</a>
              <a href="http://39.108.48.32/mipl/news/news.php?id=20240718">[中文解读]</a> 
              <br>
            </td>
          </tr>
  
      <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src='images/FinePOSE.jpg' alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>FinePOSE: Fine-Grained Prompt-Driven 3D Human Pose Estimation via Diffusion Models</papertitle>
              <br>
		        <strong>Jinglin Xu</strong>, Yijie Guo, Yuxin Peng*
              <br>
              <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</em>, 2024
		      <br>
		      <font color="red"><strong>Highlight (11.9%)</strong></font>
        <br>
	      <a href="https://pku-icst-mipl.github.io/FinePOSE_ProjectPage/">[Project Page]</a>
        <a href="https://github.com/PKU-ICST-MIPL/FinePOSE_CVPR2024">[Github]</a>
	      <a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Xu_FinePOSE_Fine-Grained_Prompt-Driven_3D_Human_Pose_Estimation_via_Diffusion_Models_CVPR_2024_paper.pdf">[Paper]</a>
	      <a href="data/FinePOSE.txt">[bibtex]</a>
               <a href="http://39.108.48.32/mipl/news/news.php?id=20240718">[中文解读]</a> 
        <br>
        </td>
        </tr>

	<tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src='images/FineSports.png' alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>FineSports: A Multi-person Hierarchical Sports Video Dataset for Fine-grained Action Understanding</papertitle>
              <br>
			  <strong>Jinglin Xu</strong>, Guohao Zhao, Sibo Yin, Wenhao Zhou, Yuxin Peng*
              <br>
              <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</em>, 2024
        <br>
	      <!-- <a href="https://finediving.ivg-research.xyz/">[Project Page]</a> -->
              <a href="https://github.com/PKU-ICST-MIPL/FineSports_CVPR2024">[Github]</a>
	      <a href="https://openaccess.thecvf.com/content/CVPR2024/papers/Xu_FineSports_A_Multi-person_Hierarchical_Sports_Video_Dataset_for_Fine-grained_Action_CVPR_2024_paper.pdf">[Paper]</a>
	      <a href="data/FineSports.txt">[bibtex]</a>
              <a href="http://39.108.48.32/mipl/news/news.php?id=20240718">[中文解读]</a> 
              <br>
            </td>
          </tr>

	

	<tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src='images/FE-VAD.png' alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>FE-VAD: High-Low Frequency Enhanced Weakly Supervised Video Anomaly Detection</papertitle>
              <br>
			  Ruoyan Pi, <strong>Jinglin Xu</strong>, Yuxin Peng*
              <br>
              <em>IEEE International Conference on Multimedia and Expo (<strong>ICME</strong>)</em>, 2024
        <br>
<!-- 	      <a href="https://finediving.ivg-research.xyz/">[Project Page]</a> -->
<!--         <a href="https://github.com/xujinglin/FineDiving">[Github]</a> -->
	      <a href="https://ieeexplore.ieee.org/document/10688326">[Paper]</a>
	      <a href="data/icme.txt">[bibtex]</a>
<!--         <a href="https://zhuanlan.zhihu.com/p/495367542">[中文解读]</a>  -->
              <br>
            </td>
          </tr>
		
	<tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src='images/finediving.png' alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>FineDiving: A Fine-grained Dataset for Procedure-aware Action Quality Assessment</papertitle>
              <br>
			        <strong>Jinglin Xu</strong>#, Yongming Rao#, Xumin Yu, Guangyi Chen, Jie Zhou, Jiwen Lu*
              <br>
              <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</em>, 2022
		      <br>
		      <font color="red"><strong>Oral (4.2%)</strong></font>
              <br>
              <a href="https://finediving.ivg-research.xyz/">[Project Page]</a>
              <a href="https://github.com/xujinglin/FineDiving">[Github]</a>
              <a href="https://arxiv.org/pdf/2204.03646.pdf">[arxiv]</a>
              <a href="data/finediving.txt">[bibtex]</a>
              <a href="https://zhuanlan.zhihu.com/p/495367542">[中文解读]</a> 
              <br>
            </td>
            </tr>
       
  <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src='images/UAL-ce.png' alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>Unintentional Action Localization via Counterfactual Examples</papertitle>
              <br>
			  <strong>Jinglin Xu</strong>#, Guangyi Chen#, Jiwen Lu*, Jie Zhou
              <br>
              <em>IEEE Transactions on Image Processing (<strong>TIP</strong>)</em>, 2022
			  <br>
	      <a href="https://ieeexplore.ieee.org/document/9758637">[Paper]</a> 
	      <a>[bibtex]</a>
            </td>
          </tr>

	<tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src='images/UAL-dpl.png' alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>Probabilistic Temporal Modeling for Unintentional Action Localization</papertitle>
              <br> <strong>Jinglin Xu</strong>#, Guangyi Chen#, Nuoxing Zhou, Wei-Shi Zheng, Jiwen Lu*
              <br>
              <em>IEEE Transactions on Image Processing (<strong>TIP</strong>)</em>, 2022
			  <br>
        <a href="https://ieeexplore.ieee.org/document/9751384">[Paper]</a>
	      <a href="data/ual_dpl.txt">[bibtex]</a>
            </td>
          </tr>
		
		
    <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src='images/TKDE_MVASM.png' alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>Multi-view K-Means Clustering with Adaptive Sparse Memberships and Weight Allocation</papertitle>
              <br>
              Junwei Han, <strong>Jinglin Xu*</strong>, Feiping Nie, Xuelong Li
              <br>
              <em>IEEE Transactions on Knowledge and Data Engineering (<strong>TKDE</strong>)</em>, 2020
			  <br>
        <a href="https://ieeexplore.ieee.org/document/9063441">[Paper]</a> 
	      <a href="https://github.com/xujinglin/MVASM">[Github]</a> 
        <a href="data/MVASM.txt">[bibtex]</a>
            </td>
          </tr>
		
		  
		    <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src='images/ijcai20.png' alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>Joint multi-view 2D convolutional neural networks for 3D object classification</papertitle>
              <br>
			  <strong>Jinglin Xu</strong>, Xiangsen Zhang, Wenbin Li, Xinwang Liu, Junwei Han
              <br>
              <em>International Joint Conference on Artificial Intelligence (<strong>IJCAI</strong>)</em>, 2020
        <br>
        <a href="https://www.ijcai.org/Proceedings/2020/0443.pdf">[Paper]</a> 
			  <a href="data/ijcai20.txt">[bibtex]</a>
            </td>
          </tr>
		  
		    <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src='images/MvNNcor.png' alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>Deep Embedded Complementary and Interactive Information for Multi-View Classification</papertitle>
              <br>
			  <strong>Jinglin Xu</strong>#, Wenbin Li#, Xinwang Liu, Dingwen Zhang, Ji Liu, Junwei Han
              <br>
              <em>AAAI Conference on Artificial Intelligence (<strong>AAAI</strong>)</em>, 2020
        <br>
        <a href="https://ojs.aaai.org/index.php/AAAI/article/view/6122">[Paper]</a>  
			  <a href="https://github.com/xujinglin/MvNNcor">[Github]</a>  
			  <a href="data/MvNNcor.txt">[bibtex]</a> 
            </td>
          </tr>


      <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src='images/TKDE_MVSVM.png' alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>Multi-view Scaling Support Vector Machines for Classification and Feature Selection</papertitle>
              <br>
              <strong>Jinglin Xu</strong>, Junwei Han, Feiping Nie, Xuelong Li
              <br>
              <em>IEEE Transactions on Knowledge and Data Engineering (<strong>TKDE</strong>)</em>, 2019
			  <br>
        <a href="https://ieeexplore.ieee.org/document/8664197">[Paper]</a> 
        <a href="data/MVSVM.txt">[bibtex]</a>
            </td>
          </tr>


        
          <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src='images/cvpr19_revisit.png' alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>Revisiting Local Descriptor based Image-to-Class Measure for Few-shot Learning</papertitle>
              <br> Wenbin Li, Lei Wang, <strong>Jinglin Xu</strong>, Jing Huo, Yang Gao, Jiebo Luo
              <br>
              <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</em>, 2019
        <br>
        <a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Li_Revisiting_Local_Descriptor_Based_Image-To-Class_Measure_for_Few-Shot_Learning_CVPR_2019_paper.pdf">[Paper]</a> 
        <a href="https://github.com/WenbinLee/DN4">[Github]</a>
			  <a href="data/cvpr19_revisit.txt">[bibtex]</a> 
            </td>
          </tr>

        
        <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src='images/aaai17_distribution.png' alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>Distribution consistency based covariance metric networks for few-shot learning</papertitle>
              <br> Wenbin Li#, <strong>Jinglin Xu</strong>#, Jing Huo, Lei Wang, Yang Gao, Jiebo Luo
              <br>
              <em>AAAI Conference on Artificial Intelligence (<strong>AAAI</strong>)</em>, 2019
        <br>
        <a href="https://ojs.aaai.org/index.php/AAAI/article/view/4885">[Paper]</a> 
        <a href="https://github.com/WenbinLee/CovaMNet">[Github]</a>
			  <a href="data/aaai19_distribution.txt">[bibtex]</a> 
            </td>
          </tr>



        <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src='images/ijcai17_mcsvm.png' alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>Feature Selection via Scaling Factor Integrated Multi-Class Support Vector Machines</papertitle>
              <br>
			  <strong>Jinglin Xu</strong>, Feiping Nie, Junwei Han
              <br>
              <em>International Joint Conference on Artificial Intelligence (<strong>IJCAI</strong>)</em>, 2017
        <br>
        <a href="https://www.ijcai.org/proceedings/2017/0442.pdf">[Paper]</a>  
			  <a href="data/ijcai17_mcsvm.txt">[bibtex]</a> 
            </td>
          </tr>

        <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src='images/ijcai17_mvfl.png' alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>Multi-view Feature Learning with Discriminative Regularization</papertitle>
              <br>
			  <strong>Jinglin Xu</strong>, Junwei Han, Feiping Nie
              <br>
              <em>International Joint Conference on Artificial Intelligence (<strong>IJCAI</strong>)</em>, 2017
        <br>
        <a href="https://www.ijcai.org/proceedings/2017/0441.pdf">[Paper]</a>  
			  <a href="data/ijcai17_mvfl.txt">[bibtex]</a> 
            </td>
          </tr>


      <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src='images/RDEKM.png' alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>Re-Weighted Discriminatively Embedded K-Means for Multi-View Clustering</papertitle>
              <br>
			  <strong>Jinglin Xu</strong>, Junwei Han*, Feiping Nie, Xuelong Li
              <br>
              <em>IEEE Transactions on Image Processing (<strong>TIP</strong>)</em>, 2017
			  <br>
        <a href="https://ieeexplore.ieee.org/abstract/document/7847419">[Paper]</a> 
        <a href="data/RDEKM.txt">[bibtex]</a> 
            </td>
          </tr>



        <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src='images/ijcai16_robust.png' alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>Robust and sparse fuzzy k-means clustering</papertitle>
              <br>
			  <strong>Jinglin Xu</strong>, Junwei Han, Kai Xiong, Feiping Nie
              <br>
              <em>International Joint Conference on Artificial Intelligence (<strong>IJCAI</strong>)</em>, 2016
        <br>
        <a href="https://www.ijcai.org/proceedings/2017/0441.pdf">[Paper]</a>  
			  <a href="data/ijcai16_robust.txt">[bibtex]</a> 
            </td>
          </tr>

        <tr>
            <td style="padding:20px;width:30%;max-width:30%" align="center">
              <img style="width:100%;max-width:100%" src='images/cvpr16_dekm.png' alt="dise">
            </td>
            <td width="75%" valign="center">
              <papertitle>Discriminatively embedded k-means for multi-view clustering</papertitle>
              <br>
			  <strong>Jinglin Xu</strong>, Junwei Han, Feiping Nie
              <br>
              <em>IEEE/CVF Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>)</em>, 2016
		      <br>
		      <font color="red"><strong>Spotlight (9.7%)</strong></font>
              <br>
        <a href="https://openaccess.thecvf.com/content_cvpr_2016/papers/Xu_Discriminatively_Embedded_K-Means_CVPR_2016_paper.pdf">[Paper]</a>  
			  <a href="data/cvpr16_dekm.txt">[bibtex]</a> 
            </td>
          </tr>
  




	    
<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Guide Students</heading>
          <p>
		    
		          <li style="margin: 5px;" >
                <b>Master Candidate:</b>
			<br>
			Wenhao Zhou (2023.09-), Yaqi Zhang (2023.09-), Xudong Zhang (2023.09-)
      <br>
      Chenyang Ma (2024.09-), Yulong Lei (2024.09-)
			<br>
			Xinghong Mu (2025.09-), Jingxuan Li (2025.09-), Jiabo Wang (2025.09-)
			<br>
			Canbin Zhang (2022.09-2025.07; with Prof. Hongmin Liu), Yuefeng Cai (2021.09-2024.07; with Prof. Hongmin Liu)
             </li>
			  <li style="margin: 5px;" >
		  <b>Ph.D. Candidate:</b>
			  <br>
			  Xueli Li (2022-; with Prof. Hongmin Liu), Hongkun Liu (2021-; with Prof. Hongmin Liu)
	     </li>
            </p>
          </td>
        </tr>
		
		<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>Professional Activities</heading>
            <p>  
		<li style="margin: 5px;" >
                <b> Editorial Board Member: Chinese Journal of Engineering (Youth), Journal of Electronics and Information Technology, Computer Science (Youth), Artificial Intelligence
              </li>
		<li style="margin: 5px;" >
                <b> Program Committee Member: IJCAI, AAAI.
              </li>
	      <li style="margin: 5px;" >
                <b>Conference Reviewer:</b> CVPR, ICCV, IJCAI, AAAI, ICME and so on.
              </li>
	      <li style="margin: 5px;" >
               <b>Journal Reviewer:</b> TPAMI, TIP, TMM, TCSVT, TCDS and so on.
              </li>
            </p>
          </td>
        </tr>
      </tbody></table>

       
      </td>
    </tr>
  </table>
</body>

</html>
